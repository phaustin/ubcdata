# Data Science opportunities provided to UBC undergraduates

Please list below, or add files to this directory to help collate the current Data Science opportunities provided to UBC undergraduates:

- [Compiled list of Undergraduate and Graduate Data Sciencey courses at UBC](ds_courses_ubc.md)
- [In the Statistics Department](https://github.ubc.ca/timberst/data-science-curriculum-notes/blob/master/current_ugrad_opportunities/stat-ugrad-data-science-opportunities.md)

## Scale for tables below

1. Demonstrate broad knowledge  
2. Demonstrate Comprehension  
3. Analyze, interpret and apply knowledge  

## Course vs. Clusters Matrix

| Cluster | DSCI 100 | CPSC 100 | CPSC 103 | MATH 210 | CPSC 340 | STAT 306 | STAT 406 | STAT 450 | EOSC 442 | PSYC 359 | MICB 405 | MICB 425 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Communication  | 2| 2 | 2 | 2 | 1 | | | | | | 1 | 1 |
| Ethics  | 0 | 1 | 0 | | 0 | | | | | | 0 | 0 |
| Computational Skills (Software)  | 1 - 2 | 0 | 2 | 3 | 3 | | | | | | 3 | 3 |
| Math & Computational Foundations (domain-specific?)  | 0 - 1 |3 |3 | 3 | 3 | | | | | | 1 | 1 |
| Statistical Reasoning  | 1 |1 | | | 2 | | | | | | 1 | 1 |
| Scientific Reasoning & process, in context  | 1 | 2 | 1 | 1 | 1 | | | | | | 2 | 3  |
| Data Management  | 1 |1 | 1 | 2 | 2 | | | | | | 1 | 1 |
| Visualization  | 2 |1 | 2 | 2 | 1 | | | | | | 3 | 3 |

## Course vs. Learning Goals Matrix 
## This set is LGs from DSCI 100. These are re-defined goals, based on the more granular actual DSCI 100 goals.  The intention is that these will be easier to map to other courses.  We will find out.  See below this table for mapping of the course-level DSCI 100 goals 

| Goal | DSCI 100 | CPSC 100 | CPSC 103 | MATH 210 | CPSC 340 | STAT 306 | STAT 406 | STAT 450 | EOSC 442 | PSYC 359 | MICB 405 | MICB 425 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| work with reproducible reports, e.g., Jupyter notebooks | 2 |0 |2 | | 3| | | | | | 1 | 3 |
| import/export tabular data, e.g., csv | 2| 0| 1| | 3| | | | | | 3 | 3 |
| scrapping data from text files, web, etc. | 1 | 0| 0| | 0| | | | | | 0 | 0 |
| understand available data structures like vectors, matrices, dataframes | 2 | 1| 3| |3 | | | | | | 2 | 2 |
| create data structures like vectors, matrices, dataframes | 1 |1 |3 | |3 | | | | | | 1 | 1 |
| understand the structure of the imported data, e.g., experiments vs measurements, diff. sample counts, etc. | 2 |0 |0 | | 3| | | | | | 1 | 1 |
| data wrangling: working with, restructuring, summarizing data subsets, e.g., diff samples per experiment | 1 |0 | 0| |2 | | | | | | 3 | 2 |
| understand why/how to restructure/reshape data, e.g., pivoting around column names  | 2 |0 | 0| |0 | | | | | | 3 | 3 |
| effectively visualize data, e.g., via scatter plots, bar charts, etc. | 2 | 2|1 | |0 | | | | | | 3 | 3 |
| understand populations, samples, observations | NA |0 |0 | |0 | | | | | | 2 | 2 |
| generate more samples from an existing sample, e.g., via bootstrapping | 2 |0 |0 | |3 | | | | | | 0 | 0 |
| analyze data via cluster analysis, e.g., k-means | 2 |1 |0 | |3 | | | | | | 3 | 0 |
| understand and apply kNN regression analysis | 2 | 0| 0| |3 | | | | | | 0 | 0 |
| understand and apply simple linear regression (i.e., single explanatory variable) | 1 |0 |0 | |3 | | | | | | 2 | 2 |
| build classifiers for data, e.g., kNN |2 | 1| 0| | 3| | | | | | 0 | 0 |
| select and understand appropriate metrics to evaluate models, e.g., MSE, accuracy, etc | 2 | 0| 0| |3 | | | | | | 0 | 0 |
| create appropriate test sets for evaluation, e.g., via splitting/cross-validations/etc | 2 |0 |0 | |3 | | | | | | 0 | 0 |
| extract attributes/features from data, define distance metrics | 1 |0 |0 | |3 | | | | | | 2 | 2 |

## Course vs. Learning Goals Matrix 
## This set is *course-level* LGs from DSCI 100. See if these map more easily to other courses 

| Goal | DSCI 100 | CPSC 100 | CPSC 103 | MATH 210 | CPSC 340 | STAT 306 | STAT 406 | STAT 450 | EOSC 442 | PSYC 359 | MICB 405 | MICB 425 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Download and scrape data off the world-wide-web. | | | | | | | | | | | 0 | 0 |
| Wrangle data from their original format into a fit-for-purpose format. | | | | | | | | | | | 3 | 3 |
| Create, and interpret, meaningful tables from wrangled data. | | | | | | | | | | | 3 | 3 |
| Create, and interpret, impactful figures from wrangled data. | | | | | | | | | | | 3 | 3 |
| Apply, and interpret the output of, a simple classifier. | | | | | | | | | | | 3 | 0 |
| Make and evaluate predictions using a simple classifier. | | | | | | | | | | | 0 | 0 |
| Apply, and interpret the output of, a simple clustering algorithm. | | | | | | | | | | | 3 | 0 |
| Apply, and interpret the output of, a regression model. | | | | | | | | | | | 3 | 3 |
| Make and evaluate predictions using a regression model. | | | | | | | | | | | 0 | 0 |
| Distinguish between in-sample prediction, out-of-sample prediction, and cross-validation. | | | | | | | | | | | 0 | 0 |
| Apply and interpret a bootstrap analysis in a regression context. | | | | | | | | | | | 0 | 0 |
| Accomplish all of the above using workflows and communication strategies that are sensible, clear, reproducible, and shareable. | | | | | | | | | | | 2 | 3 |

## This set is LGs from MDS, and are ordered based on on this group's ratings, with more "Fundamental" ratings at the top of the list, and more "Capstone" ratings at the bottom.
| Goal | DSCI 100 | CPSC 100 | CPSC 103 | MATH 210 | CPSC 340 | STAT 306 | STAT 406 | STAT 450 | EOSC 442 | PSYC 359 | MICB 405 | MICB 425 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Write pseudo-code to specify, break down, and solve problems before being translated into code.  | | | | | | | | | | | | |
| Design and write Python and R programs to: perform calculations; read and write files; and use classes, objects, methods, and Python and R libraries.  | | | | | | | | | | | | |
| Derive, manipulate and apply fundamental formulas to calculate probabilities;  | | | | | | | | | | | | |
| Write modular, easy-to-understand Python and R code that uses flow control, iteration, lists (arrays), and functions--and has appropriate style and organization.  | | | | | | | | | | | | |
| Design, perform and interpret frequentist hypothesis tests, and confidence intervals, in the context of parameter estimation.  | | | | | | | | | | | | |
| Communicate effectively through oral presentations and written reports. Distinguish between the goals of each.  | | | | | | | | | | | | |
| Outline the components of a good scientific argument, paying attention to claims, reasons, evidence, assumptions, bias, validity, reliability, etc.  | | | | | | | | | | | | |
| Analyze and determine appropriate ways of manipulating a single data table using various techniques including: filtering rows or observations based on a criterion or combination of criteria; selecting variables (columns); arranging observations or variables in a deliberate way (e.g., sorting, grouping); forming new variables from one or more existing variables; reshaping data; computing summaries on groups of observations based on one or more categorical variables.  | | | | | | | | | | | | |
| Calculate and use measures of location, spread and relative standing for a variety of discrete and continuous random variables and for their distributions;  | | | | | | | | | | | | |
| Determine which language (Python or R) is more appropriate for a given task.  | | | | | | | | | | | | |
| Explain the purpose and strengths of consistent documentation practices.  | | | | | | | | | | | | |
| Identify the components of a good experiment or data collection effort, paying attention to how the data was collected and how it is being used to construct a scientific model; identify limitations of the data and model.  | | | | | | | | | | | | |
| Identify whether a linear regression model is appropriate for a given dataset.  | | | | | | | | | | | | |
| Work proficiently with standard statistical notation for parameters, sample quantities, estimators, etc.  | | | | | | | | | | | | |
| Design and perform appropriate simulation techniques to make predictions and understand the relationship between models and data.  | | | | | | | | | | | | |
| Fit and interpret a linear regression model.  | | | | | | | | | | | | |
| Employ appropriate computing concepts and state-of-the-art Integrated Development Environments (IDEs) in the programming process.  | | | | | | | | | | | | |
| Solve problems regarding well-known (eg. Uniform, Binomial, Gaussian, Exponential) probability models;  | | | | | | | | | | | | |
| Implement static visual encodings using existing toolkits and libraries.  | | | | | | | | | | | | |
| Solve problems in probability requiring knowledge of joint probability, conditional probability and statistical independence;  | | | | | | | | | | | | |
| Manage projects by designing workflows for self-documentation, reproducibility, and collaboration; organize files with appropriate naming conventions; manage paths and dependencies.  | | | | | | | | | | | | |
| Work effectively with teams and domain experts on data science problems.  | | | | | | | | | | | | |
| Apply large sample results including the Law of Large Numbers and the Central Limit Theorem.  | | | | | | | | | | | | |
| Define Type I and Type II Errors, Power, and carry out a simple calculation of Power for a univariate hypothesis test mean.  | | | | | | | | | | | | |
| Integrate popular R and Python libraries into their code; select appropriate libraries for a given task.  | | | | | | | | | | | | |
| Analyze existing static visual encodings in terms of marks and channels, spatial arrangement, and color broken down into luminance, saturation, and hue.  | | | | | | | | | | | | |
| Write effectively on technical data science topics for a nontechinal audience.  | | | | | | | | | | | | |
| Present data science results to diverse audiences and recommend subsequent action to decision makers.  | | | | | | | | | | | | |
| Identify trade-offs in security and privacy.  | | | | | | | | | | | | |
| Apply ethical theories to case studies. Consider privacy, human dignity, harm, the public good, legal issues, the role of ethics boards, and consent.  | | | | | | | | | | | | |
| Explain why good security is not a product, but rather a process and a mindset.  | | | | | | | | | | | | |
| Argue for why security is complex and difficult, and why perfect security may be unachievable.  | | | | | | | | | | | | |
| Identify situations in which data is sensitive, assess the risks, and articulate a reasoned response.  | | | | | | | | | | | | |
| Identify probability models for two random variables and calculate covariance, correlation and conditional means;  | | | | | | | | | | | | |
| Diagnose and troubleshoot programming and development environment problems, and explain how such problems can be avoided.  | | | | | | | | | | | | |
| Apply fundamental algorithms such as sorting and searching, including iterative and recursive algorithms, using lists.  | | | | | | | | | | | | |
| Critique a specific regression model applied to a given dataset on the basis of both diagnostic plots and hypothesis tests.  | | | | | | | | | | | | |
| Explain, with examples, the key differences between a supervised and an unsupervised learning problem.  | | | | | | | | | | | | |
| Estimating model parameters using MLE  | | | | | | | | | | | | |
| Correctly apply robust estimators to determine whether outliers are present in the data, and explain the implications of their removal on subsequent analyses of the data.  | | | | | | | | | | | | |
| Analyze data interactively using read-eval-print-loop (REPL) processes; write scripts for non-interactive use; use tools and work styles to create fluidity between these two modes (e.g., RStudio IDE, iPython).  | | | | | | | | | | | | |
| Discuss the advantages and disadvantages of using non-parametric regression methods.  | | | | | | | | | | | | |
| Fit a mixed effects model when appropriate, and interpret the corresponding parameter estimates.  | | | | | | | | | | | | |
| Scrape data from websites and access data using application programming interfaces (APIs) where available.  | | | | | | | | | | | | |
| Analyze the scalability and trade-offs of various basic algorithms and data structures, using Big-O notation.  | | | | | | | | | | | | |
| Explain how the concepts of generalization error and overfitting of training data are essential to the performance of a classification or regression model.  | | | | | | | | | | | | |
| Customize and configure software platforms used in the Data Science program.  | | | | | | | | | | | | |
| Explain whether a visual encoding is perceptually appropriate for a specific combination of task and data.  | | | | | | | | | | | | |
| Apply basic discrete optimization methods such as dynamic programming.  | | | | | | | | | | | | |
| Describe and manipulate table, network, and spatial data; transform data into a form suitable for the intended abstract task of the visualization user.  | | | | | | | | | | | | |
| Compare and contrast linear regression, GLMs, non-linear regression, and non-parametric regression.  | | | | | | | | | | | | |
| Communicate uncertainty to diverse audiences.  | | | | | | | | | | | | |
| Identify appropriate alternatives for problems where a linear regression model should not be used, and discuss the specific difficulties that are being addressed.  | | | | | | | | | | | | |
| Identify the pros and cons of situations in which data was collected for one purpose and later analyzed for other purposes.  | | | | | | | | | | | | |
| Explain why using a different (better) algorithm for a problem can result in a much, much bigger performance improvement than tweaking the algorithm already being used.  | | | | | | | | | | | | |
| Avoid the pitfalls of overfitting and reusing test sets.  | | | | | | | | | | | | |
| Perform k-fold cross validation and bootstrapping based on the training data.  | | | | | | | | | | | | |
| Use version control software (e.g., Git) including distributed version control and remote servers (e.g., GitHub).  | | | | | | | | | | | | |
| Apply successfully K-means and K-medoids, hierarchical and model-based clustering, including the EM algorithm.  | | | | | | | | | | | | |
| Distinguish between experimentally-generated data and observational data, with particular reference to the strength of ensuing statistical conclusions.  | | | | | | | | | | | | |
| Solve problems regarding the Bivariate Gaussian distributions;  | | | | | | | | | | | | |
| Apply logistic regression to classification, and explain the key differences between regression and classification models.  | | | | | | | | | | | | |
| Select and justify the use of elementary data structures such as arrays, hash tables, trees, and simple graphs.  | | | | | | | | | | | | |
| Perform dynamic reporting functions such as integrating narrative, code, data, numerical results, and visual results; create reproducible reports and workflows (e.g., R Markdown, Project Jupyter).  | | | | | | | | | | | | |
| Handle common and tricky data types; manipulate text, dates/times, strings, and regular expressions; detect and handle duplicates and outliers.  | | | | | | | | | | | | |
| Determine appropriate manipulations for two-table data, including lookups and joins with suitably-selected columns.  | | | | | | | | | | | | |
| Compare and contrast classifiers that generate binary predictions and those that compute probabilistic predictions; derive the probabilistic predictions of the Naive Bayes method.  | | | | | | | | | | | | |
| Apply graphical models as a probabilistic approach to model complex, large-scale problems.  | | | | | | | | | | | | |
| Make use of pairwise preference data via ranking algorithms  | | | | | | | | | | | | |
| Identify when recommender systems may be useful and apply them in these circumstances.  | | | | | | | | | | | | |
| Apply basic techniques in active data acquisition, and explain under what circumstances these techniques are worth using.  | | | | | | | | | | | | |
| Explain and justify methods to validate visualization design effectiveness including computational benchmarks, field studies on deployed software, and qualitative discussion of visual results.  | | | | | | | | | | | | |
| Analyze interactive visualizations in terms of approaches to handling complexity: dynamic change over time, partitioning into multiple views, data reduction within a single view, and the derivation of new data.  | | | | | | | | | | | | |
| Design new interactive visualizations for complex datasets.  | | | | | | | | | | | | |
| Implement interactive visualizations using existing toolkits and libraries.  | | | | | | | | | | | | |
| Explain the trade-offs of using animation vs juxtaposed views vs derived data.  | | | | | | | | | | | | |
| Write well-formed XML; use XPath and XQuery to write simple queries over an XML repository (i.e., XML database).  | | | | | | | | | | | | |
| Connect the concepts in databases to those of distributed computing  | | | | | | | | | | | | |
| Use an Entity-Relationship (ER) Diagram to determine the entities, relationships, attributes, data types, primary keys, foreign keys, etc., for a given database application; translate an ER Diagram to a relational database schema.  | | | | | | | | | | | | |
| Write programs containing embedded SQL statements to communicate with and query a database, thereby generating reports requiring more complicated logic and calculations than what is possible via stand-alone SQL.  | | | | | | | | | | | | |
| Explain basic concepts of the Map Reduce paradigm.  | | | | | | | | | | | | |
| Write SQL statements to define, query, and update tables in a database.  | | | | | | | | | | | | |
| Explain and apply appropriately different matrix decompositions, including Singular Value Decomposition, Cholesky Decomposition, QR and LU.  | | | | | | | | | | | | |
| Parallelize computations in an environment such as ipyparallel.  | | | | | | | | | | | | |
| Choose appropriately between fixed-effect and random-effect regression models.  | | | | | | | | | | | | |
| Apply the principle of “block what you can, randomize what you cannot” in designing an A/B testing experiment.  | | | | | | | | | | | | |
| Author web content for public access.  | | | | | | | | | | | | |
| Host a simple application on a cloud computing platform such as Amazon’s EC2.  | | | | | | | | | | | | |
| Automate data science workflows (using e.g., Make).  | | | | | | | | | | | | |
| Implement good security and privacy practices in data storage, use, and reporting.  | | | | | | | | | | | | |
| Fit and interpret regression models for observational data, with particular reference to adjustment for potential confounding variables.  | | | | | | | | | | | | |
| Apply and correctly interpret relevant visualization tools to the analysis (e.g., heatmaps and dendrograms).  | | | | | | | | | | | | |
| Explain and apply appropriately the following dimension-reduction methods: principal components, factor analysis and multidimensional scaling. Explain their differences and similarities.  | | | | | | | | | | | | |
| Design new static visual encodings that use space and color channels appropriately according to principles of perceptual effectiveness and by matching channel type to attribute type for quantitative versus categorical attributes.  | | | | | | | | | | | | |
| Explain, with examples, the key differences between an unsupervised learning problem and a supervised learning problem, as well as the concept of training data.  | | | | | | | | | | | | |
| Construct and apply a decision tree classification model, and explain how the concept of generalization error is tied to the depth of a decision tree.  | | | | | | | | | | | | |
| Ingest non-tabular data (e.g. from XML or JSON) into a recursive list. Extract and wrangle selected info into a simpler data structure (e.g. vector or data frame).  | | | | | | | | | | | | |
| Evaluate the quality of a statistical model in order to do model/feature selection.  | | | | | | | | | | | | |
| Diagnose/understand/address overfitting and underfitting.  | | | | | | | | | | | | |
| Specify and interpret interaction terms and nonlinear terms.  | | | | | | | | | | | | |
| Identify an interesting data science question for which data are available or obtainable.  | | | | | | | | | | | | |
| Define the scope of a possible solution, identify units of work (deliverables), and estimate the effort required.  | | | | | | | | | | | | |
| Design and implement a solution to a problem in data science that can be completed within 6 weeks.  | | | | | | | | | | | | |
| Function effectively in teams: communicate productively between team members, identify sub-problems that could be worked on individually by team members, and integrate contributions of team members into a final product.  | | | | | | | | | | | | |
| Document and present (using written, oral, and visual means) the process and results from a solution to a data science problem.  | | | | | | | | | | | | |
| Evaluate or assess a solution to a data science problem, and compare it with alternative approaches.  | | | | | | | | | | | | |
| Apply various schemes to ensemble multiple classifiers to boost performance.  | | | | | | | | | | | | |
| Deploy neural networks on a GPU.  | | | | | | | | | | | | |
| Explain, with examples, the main inferential tasks related to spatial or temporal data, and how the spatial or temporal associations make it possible to borrow statistical tools.  | | | | | | | | | | | | |
| Understand the ideas of autocorrelation and correlated errors, and be able to explain the importance of these ideas for temporal and spatial modelling.  | | | | | | | | | | | | |
| Fit temporal, spatial, and spatio-temporal models by implementing them in a probabilistic programming language, and interpret the results.  | | | | | | | | | | | | |
| Demonstrate how various decision trees can be combined into a random forest classifier, and explain the role of bagging in such classifiers.  | | | | | | | | | | | | |
| Train neural networks for performing regression and classification tasks with deep learning.  | | | | | | | | | | | | |
| Apply relevant visualization tools and draw correct conclusions from the analysis.  | | | | | | | | | | | | |
| Use appropriate statistical libraries and packages for performing Bayesian inference (e.g., PyMC).  | | | | | | | | | | | | |
| Apply Bayesian statistics to regression models.  | | | | | | | | | | | | |
| Use Bayesian reasoning when modeling data.  | | | | | | | | | | | | |
| Compare and contrast Bayesian and frequentist methods, and evaluate their relative strengths.  | | | | | | | | | | | | |
| Avoid the pitfalls of multiple comparisons by using the proper corrections.  | | | | | | | | | | | | |
| Interpret software licenses to understand how others' projects can be used  | | | | | | | | | | | | |
| Specify, implement, and use a data abstraction in Python  | | | | | | | | | | | | |
| Apply and use feature selection methods (e.g., Lasso, elastic nets).  | | | | | | | | | | | | |
| Complete a project that demonstrates appropriate use of collaborative software development processes and tools, including: 1) packaging code for use by others, including the specification of dependencies/requirements. 2) using distributed version control and issue tracking to manage the multi-person project. 3) writing comprehensive test suites. 4) handling exceptional cases in a function or method with exceptions or assert statements 5) selecting software licenses that best suit the project  | | | | | | | | | | | | |
| Explain how the ROC is generated, and how the area under the ROC curve (AUC) can be used for comparing models.  | | | | | | | | | | | | |
| Build a k-th nearest-neighbor (kNN) classifier; compare and contrast parametric and non-parametric classification models.  | | | | | | | | | | | | |
| Deploy support vector machine (SVM) classifiers, and explain how kernel functions are used in such classifiers  | | | | | | | | | | | | |
